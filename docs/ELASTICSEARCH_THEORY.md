# Elasticsearch: Теоретичний огляд та перспективи розвитку

## 1. Що таке Elasticsearch?

Elasticsearch — це розподілена пошукова та аналітична система з відкритим вихідним кодом, створена для швидкості, масштабованості та застосувань штучного інтелекту (1). Як платформа для отримання даних, вона зберігає структуровані, неструктуровані та векторні дані в режимі реального часу, забезпечуючи швидкий гібридний та векторний пошук (1). Система побудована на базі Apache Lucene — потужної бібліотеки для індексування, пошуку, отримання та оновлення документів, а також текстового аналізу (2). Саме бібліотека Apache Lucene є ядром Elasticsearch і забезпечує основну функціональність пошукової системи (2). У серпні 2024 року ліцензія GNU Affero General Public License була додана до Elasticsearch версії 8.16.0 як опція, що знову зробило Elasticsearch вільним програмним забезпеченням з відкритим вихідним кодом (1).

## 2. Архітектура та принцип роботи

### 2.1 Інвертований індекс

Інвертований індекс є фундаментальною структурою даних, яка широко використовується в пошукових системах для відображення вмісту на його розташування в базі даних або колекції документів (3). На відміну від традиційного прямого індексу, який відображає документи на терміни, які вони містять, інвертований індекс перевертає це відношення, відображаючи терміни на документи, в яких вони з'являються (3). Такий підхід робить пошук надзвичайно швидким, оскільки користувачі шукають за термінами, і наявність готового списку значень термін-документ прискорює процес запиту (3).

Інвертований індекс складається з двох ключових підструктур: словника термінів, який групує всі терміни, знайдені в документах, у відсортований список, та списку публікацій (postings list), який створює список кожного терміна із зазначенням документів, де цей термін з'являється (3). Оскільки терміни в словнику відсортовані, можна швидко знайти термін за допомогою бінарного пошуку, а потім його входження в структурі публікацій (3).

### 2.2 Процес індексування

Коли документ зберігається в Elasticsearch, паралельно відбуваються два процеси: у першому необроблений документ зберігається в індексі, а в другому кожен документ проходить фазу аналізу перед збереженням в інвертованому індексі (3). Токенізація є початковим кроком у процесі індексування, де документ розбивається на окремі токени або терміни шляхом розділення тексту на дискретні одиниці, зазвичай слова або фрази, на основі попередньо визначених розділювачів, таких як пробіли та розділові знаки (3).

Lucene будує інвертований індекс, використовуючи Skip-Lists на диску, а потім завантажує відображення для індексованих термінів у пам'ять за допомогою Finite State Transducer (FST) (4). Варто зазначити, що Lucene не обов'язково завантажує всі індексовані терміни в RAM (4). Використовуючи Skip-Lists, можна переходити від одного результату до іншого, що робить можливими запити на множини та, особливо, діапазонні запити, подібно до B-дерев (4).

### 2.3 Сегментна архітектура

Записані файли складають сегмент індексу, а індекс Lucene складається з одного або більше незмінних сегментів індексу, які по суті є "міні-індексами" (4). При пошуку Lucene виконує пошук у кожному сегменті, фільтрує будь-які видалення та об'єднує результати з усіх сегментів (4). Однією з причин того, чому Lucene досить швидкий в індексуванні та пошуку до певної міри, є те, що сегменти індексу незмінні, а зміна біта в структурі даних живих документів робить видалення видимими в пошуку дуже швидко (4).

Важливо розуміти різницю між індексом Elasticsearch та індексом Lucene: індекс Elasticsearch складається з шардів (індексів Lucene), а індекс Lucene складається з інвертованого індексу, який містить окремі токени (5). Elasticsearch базується на Lucene, і кожен шард Elasticsearch є повноцінним індексом Lucene, оскільки в Lucene немає концепції шардів (5).

## 3. Застосування в електронній комерції

### 3.1 Чому Elasticsearch для інтернет-магазину?

Elasticsearch використовує інвертовані індекси та індексування майже в реальному часі, забезпечуючи повернення результатів запитів продуктів за мілісекунди, що критично важливо для електронної комерції (6). Система є наріжним каменем ринку електронної комерції, який цінують за потужні можливості пошуку та аналітики, підтримувані сильною спільнотою відкритого коду (7).

### 3.2 Вплив пошуку на конверсію

Статистика чітко демонструє критичну важливість якісного пошуку для електронної комерції. До 30% відвідувачів інтернет-магазинів використовують внутрішній пошук по сайту, і ці користувачі пошуку в 2-3 рази частіше здійснюють покупку (8). При цьому 39% покупців знаходяться під впливом релевантного пошуку, а 43% клієнтів роздрібної торгівлі одразу переходять до рядка пошуку на веб-сайті (8). Показовим є те, що коли лише 15% відвідувачів використовують пошук, але вони генерують 45% доходу, користувачі пошуку стають найціннішими клієнтами магазину (8).

Дослідження показують значне покращення бізнес-показників завдяки оптимізації пошуку. Кейс-стаді продемонстрували збільшення коефіцієнта конверсії на 43% від оптимізації пошуку по сайту (8). Відвідувачі, які використовують пошук, конвертувалися на рівні 4,63% проти середнього показника веб-сайтів 2,77%, що в 1,8 рази ефективніше (8). Загалом коефіцієнти конверсії через пошук по сайту можуть бути до 50% вищими за середній показник (8). Додатково, автозаповнення може збільшити продажі та конверсії до 24%, а на деяких сайтах користувачі пошуку становлять приблизно 40% загального доходу (8).

### 3.3 Наслідки поганого пошуку

Недостатня увага до якості пошуку має серйозні негативні наслідки для бізнесу. Дослідження показують, що 72% сайтів повністю не відповідають очікуванням користувачів щодо пошуку (9). Коли користувачі не можуть знайти те, що шукають, приблизно 12% негайно переходять на сайт конкурента (9). Ще більш тривожним є те, що 68% клієнтів заявляють, що не повернуться на сайт з поганим досвідом пошуку, а 78% споживачів відзначають, що функція пошуку на сайтах роздрібної торгівлі іноді надає нерелевантні товари (9). За оцінками, лише в США інтернет-магазини втрачають 300 мільярдів доларів через поганий досвід онлайн-пошуку (9).

## 4. Продуктивність та порівняльні тести

### 4.1 Офіційні бенчмарки та методологія тестування

Офіційні бенчмарки Elasticsearch виконуються фреймворком Rally, націлюючись на кластери, що працюють на останній snapshot-збірці Elasticsearch з основної гілки (10). Середовища бенчмарків відтворюються щодня на віртуальних машинах AWS або GCP, де одна VM хостить драйвер бенчмарку Rally, а інші хостять вузли Elasticsearch (10). Важливо зазначити, що це навмисно не є бенчмарками масштабованості, а їх мета — допомогти розробникам Elasticsearch виявляти регресії продуктивності (10).

### 4.2 Порівняння з OpenSearch

Комплексне тестування між Elasticsearch та OpenSearch проводилося в критичних областях використання, включаючи пошук для випадків використання електронної комерції з типовою функціональністю рядка пошуку (11). Результати показали значну перевагу Elasticsearch: система виявилася на 76% швидшою у виконанні текстових запитів порівняно з OpenSearch (11). Текстові запити є фундаментальними та критичними для повнотекстового пошуку, який є основною функцією Elasticsearch (11).

Крім переваги у швидкості, Elasticsearch також продемонстрував кращу ефективність використання ресурсів. З налаштуваннями за замовчуванням Elasticsearch використовував на 37% менше дискового простору, а при використанні параметра best_compression на обох системах Elasticsearch все ще був на 13% ефективніший за простором (11).

### 4.3 Бізнес-вплив

За даними дослідження, проведеного на замовлення Forrester Consulting, клієнти, що використовують Elasticsearch, реалізували покращення доходу на 5% до третього року використання та зниження загальної вартості володіння на 25% (6). Ці результати підтверджують економічну доцільність інвестицій у якісну пошукову інфраструктуру.

## 5. Гібридний пошук

### 5.1 Концепція гібридного пошуку

Гібридний пошук являє собою комбінацію ключового слова, лексичного або BM25 (алгоритм ранжування, що визначає релевантність) та семантичного пошуку (12). Такий підхід покращує точність пошуку, поєднуючи сильні сторони семантичного пошуку та традиційного пошуку, балансуючи семантичне розуміння та врахування точних термінів запиту для покращення користувацького досвіду пошуку (12).

Рекомендований спосіб використання гібридного пошуку в Elastic Stack передбачає дотримання робочого процесу semantic_text (13). Цільовий індекс міститиме як ембединги для семантичного пошуку, так і оригінальне текстове поле для повнотекстового пошуку, що дозволяє комбінувати обидва підходи (13).

### 5.2 Методи об'єднання результатів

Для об'єднання лексичних та семантичних результатів пошуку гібридного запиту обидва набори результатів потрібно злити таким чином, щоб зберегти відносну релевантність отриманих документів (14). Існують два поширені методи такого злиття.

Перший метод — Reciprocal Rank Fusion (RRF) — використовує алгоритм взаємного рангового злиття. RRF є технікою, яка об'єднує ранжування з семантичних та лексичних запитів, надаючи більшу вагу результатам, які займають високі позиції в обох пошуках, що забезпечує збалансовані та релевантні фінальні результати (14).

Другий метод — Convex Combination (CC), також називаний лінійною комбінацією — прагне поєднати нормалізовану оцінку результатів лексичного пошуку та результатів семантичного пошуку з відповідними вагами (14). Ваги між 0 та 1 використовуються для зниження впливу відповідного запиту, тоді як ваги більше 1 використовуються для його підсилення (14).

### 5.3 Вибір типу пошуку

Лексичний пошук чудово підходить, коли є контроль над структурованими даними і користувачі більш-менш чітко розуміють, що шукають (14). Семантичний пошук, однак, забезпечує чудову підтримку, коли потрібно зробити неструктуровані дані доступними для пошуку і користувачі точно не знають, що саме шукають (14). Гібридний пошук поєднує найкраще з обох світів: він комбінує точність та функціональність текстового пошуку BM25 з семантичним розумінням векторного пошуку, що призводить як до кращого recall, так і до кращої загальної релевантності (12).

## 6. Векторний пошук та kNN

### 6.1 Основи kNN пошуку

Пошук k-найближчих сусідів (kNN) знаходить k найближчих векторів до вектора запиту, використовуючи метрику подібності, таку як косинусна подібність або L2 норма (15). За допомогою kNN пошуку Elasticsearch можна отримувати результати на основі семантичного значення, а не точних збігів ключових слів (15). Це відкриває нові можливості для пошуку, де важливе не точне співпадіння слів, а смислова близькість контенту.

Elasticsearch підтримує два методи для kNN пошуку: приблизний kNN та точний kNN методом грубої сили (15). Приблизний kNN забезпечує швидкий, масштабований пошук подібності з використанням опції knn, запиту knn або knn retriever, і ідеально підходить для більшості виробничих навантажень (15). Точний kNN використовує запит script_score з векторною функцією і найкраще підходить для малих наборів даних або випадків, коли потрібне точне оцінювання (15). Приблизний kNN пропонує низьку затримку та хорошу точність, тоді як точний kNN гарантує точні результати, але погано масштабується для великих наборів даних (15).

### 6.2 Алгоритм HNSW

Elasticsearch використовує векторний пошук з алгоритмом HNSW (Hierarchical Navigable Small World) через Apache Lucene (16). HNSW будує граф, де подібні вектори з'єднані, забезпечуючи ефективний пошук (16). Цей алгоритм є популярним вибором для векторного пошуку, оскільки він досить простий, добре показує себе на порівняльних бенчмарках алгоритмів векторного пошуку та підтримує інкрементальні вставки (16).

HNSW граф є шаруватою структурою даних, де всі вектори присутні в нижньому шарі (шар 0), причому кожен вектор представлений вузлом графа (16). Ймовірність появи вектора в кожному шарі зменшується логарифмічно при переході до вищих шарів, тому кожен шар має менше векторів, ніж шар під ним (16). HNSW є типом алгоритму приблизних найближчих сусідів (ANN), що означає, що він надає наближення справжніх найближчих сусідів, а не гарантію (16).

### 6.3 Продуктивність векторного пошуку

Порівняльні тести демонструють вражаючу перевагу приблизного пошуку над точним. У порівнянні на наборі даних з 1 мільйона векторів зображень з 128 вимірами ANN пошук досяг 849 запитів на секунду порівняно з лише 5,257 для точних script_score запитів (17). Таким чином, ANN пошук на порядки швидший за точний підхід, при цьому recall становить близько 95%, тобто в середньому знаходиться понад 9 з 10 справжніх найближчих сусідів (17).

Для оптимізації продуктивності рекомендується використовувати dot_product замість косинусної подібності при розгортанні векторного пошуку у виробництві (15). Використання скалярного добутку уникає необхідності обчислювати величини векторів для кожного обчислення подібності, оскільки вектори нормалізуються заздалегідь до величини 1 (15). Це може покращити швидкість пошуку та індексування в 2-3 рази (15).

### 6.4 Параметри та компроміси

Два параметри, що використовуються для побудови HNSW графа, — це M (максимальна кількість зв'язків вузла) та ef_construction (скільки вузлів шукати при додаванні нового вектора) (16). Збільшення M робить пошук точнішим за рахунок збільшення кількості пов'язаних сусідів та шарів, але збільшує використання диска та пам'яті, затримку вставки та затримку пошуку (16). Збільшення ef_construction виконує більш вичерпний пошук сусідів, але збільшує затримку вставки (16).

Обхід HNSW графа спричиняє багато випадкових звернень до пам'яті, тому для ефективної роботи набори даних повинні поміщатися в page cache, що вимагає розміру RAM на основі розміру набору векторних даних (18). Згідно з документацією Elastic, для підтримки оптимальної продуктивності алгоритм HNSW Lucene вимагає, щоб весь індекс поміщався в page cache, тобто має бути достатньо RAM для того, щоб весь індекс залишався резидентним у пам'яті (18).

## 7. Пошук по зображеннях: Перспективи розвитку

### 7.1 Поточні можливості Elasticsearch

Якщо є набір даних зображень, перетворених у вектори за допомогою нейронної мережі, можна використовувати kNN пошук для знаходження зображень, найбільш схожих на зображення запиту (15). Наприклад, якщо надати векторне представлення зображення "піци", kNN може допомогти знайти інші візуально схожі зображення, такі як млинці та, можливо, паста (15). kNN пошук призначений для знаходження найближчих точок даних у векторному просторі, тому він підходить для пошуку подібності як для текстових, так і для графічних ембедингів (15).

При реалізації пошуку подібності зображень з використанням платформи Elastic векторний пошук та NLP нативно інтегровані (19). Додаток може нативно взаємодіяти з усіма залученими компонентами, а кластер Elasticsearch може виконувати kNN пошуки та NLP inference (19). Модель CLIP, яку використовували команди Elastic для прототипування програми пошуку подібності зображень, розповсюджується OpenAI і забезпечує хорошу відправну точку (19).

### 7.2 Модель CLIP від OpenAI

CLIP (Contrastive Language-Image Pre-training) — це сучасна модель, представлена OpenAI у лютому 2021 року (20). Це нейронна мережа, навчена на приблизно 400 мільйонах пар тексту та зображень (20). CLIP ефективно вивчає візуальні концепції з природного мовного нагляду і може застосовуватися до будь-якого бенчмарку візуальної класифікації, просто надаючи назви візуальних категорій для розпізнавання, подібно до можливостей "zero-shot" GPT-2 та GPT-3 (21).

Архітектурно CLIP складається з двох моделей, навчених паралельно: 12-шарового текстового трансформера для побудови текстових ембедингів та ResNet або vision transformer (ViT) для побудови ембедингів зображень (20). Усі вектори мають 512 вимірів і можуть бути представлені в одному векторному просторі, що означає, що схожі зображення та текст створюють вектори, які з'являються близько один до одного (20). Ембединги CLIP для зображень та тексту поділяють один простір, що дозволяє безпосередньо порівнювати дві модальності (20). Це досягається навчанням моделі зближувати пов'язані зображення та тексти, одночасно відштовхуючи непов'язані (20).

Нейронна мережа CLIP здатна проектувати як зображення, так і текст в один і той же латентний простір, що означає, що їх можна порівнювати за допомогою метрики подібності, такої як косинусна подібність (20). CLIP можна використовувати для пошуку Text-to-Image, Image-to-Text, Image-to-Image та Text-to-Text (20). Крім пошуку тексту та зображень, CLIP можна застосовувати до класифікації зображень, генерації зображень, пошуку подібності зображень, ранжування зображень, відстеження об'єктів, управління роботами, підписування зображень та багатьох інших завдань (20).

Важливою перевагою CLIP є надання можливостей zero-shot, що дозволяє адаптувати попередньо навчену модель безпосередньо без використання transfer learning для fine-tuning моделі (20). Однак CLIP від OpenAI має певні обмеження: дуже обмежена ємність текстового введення, що приймає максимум 77 токенів, але емпіричний аналіз показує, що на практиці модель не використовує більше 20 токенів для створення ембедингів (20). Це пов'язано з тим, що CLIP навчався на зображеннях з підписами, а підписи зазвичай дуже короткі (20).

### 7.3 Традиційні CNN для витягування ознак

При виконанні витягування ознак глибокого навчання попередньо навчена мережа розглядається як довільний екстрактор ознак, дозволяючи вхідному зображенню поширюватися вперед, зупиняючись на попередньо визначеному шарі та беручи виходи цього шару як ознаки (22). Таким чином можна використовувати робастні, дискримінативні ознаки, вивчені CNN, і застосовувати їх для розпізнавання класів, на яких CNN ніколи не навчалася (22).

Моделі VGG були розроблені Visual Geometry Group в Оксфордському університеті, з варіантами VGG-16 та VGG-19 (23). VGGNet використовує малі 3x3 згорткові фільтри з кроком 1 та відступом 1, що дозволяє створювати глибшу мережу, зберігаючи простішу структуру (23). Архітектура використовує прості 3x3 згортки і широко застосовується для загальної класифікації зображень та витягування ознак (23).

ResNet, скорочення від Residual Network, — це архітектура глибокого навчання, яка ввела концепцію залишкового навчання і була запропонована Kaiming He, Xiangyu Zhang, Shaoqing Ren та Jian Sun у статті "Deep Residual Learning for Image Recognition" у 2015 році (24). Ключова інновація в ResNet — це введення skip-з'єднань або shortcut-з'єднань, які дозволяють мережі обходити один або більше шарів (24). Ці з'єднання забезпечують потік інформації від ранніх шарів до пізніших, допомагаючи пом'якшити проблему деградації при навчанні глибоких мереж (24). Хоча ResNet значно глибша за VGG16 та VGG19, розмір моделі насправді суттєво менший завдяки використанню глобального усередненого пулінгу замість повнозв'язних шарів, що зменшує розмір моделі до 102MB для ResNet50 (22).

В останні роки значна увага приділялася використанню CNN для подібності зображень, враховуючи їх ієрархічну природу, яка означає, що вони здатні автоматично визначати найкраще представлення для навчання або класифікації (25). На відміну від традиційних методів, які фокусуються на ознаках нижчого рівня, CNN здатні моделювати більш абстрактні представлення (25).

### 7.4 Розгортання ML моделей в Elasticsearch

Elasticsearch підтримує трансформери та NLP моделі, що є поширеним випадком використання в контексті пошукових додатків (26). Можна надавати навчені моделі, які не створені аналітикою data frame, але відповідають відповідній JSON-схемі, і використовувати сторонні моделі для виконання завдань обробки природної мови (26).

Бібліотека Eland надає простий інтерфейс для завантаження ML моделей в Elasticsearch, за умови, що вони були навчені з використанням PyTorch (26). Використовуючи нативну бібліотеку libtorch та очікуючи моделі, експортовані як представлення TorchScript, Elasticsearch уникає запуску інтерпретатора Python під час виконання inference моделі (26). Є три варіанти використання Eland для завантаження моделі: командний рядок, Docker та з власного Python-коду (26). Docker є менш складним варіантом, оскільки не вимагає локальної установки Eland та всіх його залежностей (26).

При використанні опції --start в кінці команди імпорту eland Elasticsearch розгорне модель на всіх доступних вузлах машинного навчання та завантажить модель у пам'ять (26). Якщо є кілька моделей, можна використовувати інтерфейс Kibana Machine Learning > Model Management для керування запуском та зупинкою моделей (26).

Після розгортання навченої моделі в кластері її можна використовувати для виконання завдань обробки природної мови в конвеєрах ingestion (27). Inference processors використовують навчені ML моделі, тому потрібно використовувати вбудовану модель або розгорнути навчену модель в кластері для використання цієї функції (27).

ELSER (Elastic Learned Sparse EncodeR) можна використовувати через Elastic Inference Service (EIS) (28). При використанні ELSER на EIS не потрібно керувати інфраструктурою та ресурсами, необхідними моделі ELSER, оскільки вона не використовує ресурси вузлів користувача (28). Увімкнення автомасштабування через адаптивні розподіли або адаптивні ресурси дозволяє Elasticsearch масштабувати доступні ресурси розгортання ELSER на основі навантаження на процес (28).

## 8. Реалізація пошуку по зображеннях: Потенційні підходи

### 8.1 Підхід з використанням готових моделей (CLIP)

Використання моделі CLIP є найшвидшим способом впровадження пошуку по зображеннях. Основна перевага полягає в тому, що CLIP надає можливості zero-shot, що дозволяє адаптувати попередньо навчену модель безпосередньо без необхідності fine-tuning (20). Крім того, єдиний векторний простір для тексту та зображень дозволяє шукати зображення за текстовим описом, що є потужною функцією для електронної комерції. Реалізація передбачає конвертацію всіх зображень продуктів у вектори за допомогою CLIP, збереження векторів в Elasticsearch як dense_vector полів, та використання kNN пошуку для знаходження найбільш схожих векторів при пошуковому запиті.

### 8.2 Fine-tuning існуючих моделей

Альтернативний підхід передбачає адаптацію існуючих моделей під специфічний домен, наприклад, електроніку або одяг. Це забезпечує кращу точність для конкретних категорій товарів за рахунок оптимізації моделі під власний набір даних. Реалізація включає використання VGG-16 або ResNet-50 як backbone, виконання transfer learning на власному наборі даних продуктів та витягування ознак з передостаннього шару мережі.

### 8.3 Розробка власної моделі

Для організацій з особливими вимогами можливий підхід розробки власної моделі з нуля. Це забезпечує повний контроль над архітектурою та можливість оптимізації під специфічні вимоги бізнесу. Однак такий підхід вимагає значних обчислювальних ресурсів, великого набору даних для навчання та тривалого часу розробки. Рекомендована архітектура включає ResNet-50 або EfficientNet як backbone, розмір ембедингу 256-512 вимірів, Triplet loss або Contrastive loss як функцію втрат та аугментацію даних для покращення генералізації.

### 8.4 Інтеграція з Elasticsearch

Для всіх підходів інтеграція з Elasticsearch виглядає однаково і базується на використанні типу поля dense_vector (15). Необхідно створити індекс з полем типу dense_vector, вказавши кількість вимірів відповідно до обраної моделі, увімкнувши індексацію та налаштувавши метрику подібності (зазвичай cosine). Під час завантаження продуктів виконується індексація ембедингів зображень, а при пошуку використовується kNN запит для знаходження візуально схожих продуктів.

## 9. Висновки

Elasticsearch є потужним та гнучким інструментом для реалізації пошуку в інтернет-магазинах, що підтверджується численними дослідженнями та статистикою. Користувачі пошуку в 2-3 рази частіше здійснюють покупку (8), а оптимізація пошуку може збільшити конверсію на 43% (8). При цьому 72% сайтів не відповідають очікуванням користувачів щодо пошуку (9), що створює значний потенціал для конкурентної переваги.

Технічні можливості Elasticsearch охоплюють весь спектр сучасних пошукових технологій: від традиційного повнотекстового пошуку на базі інвертованого індексу до гібридного пошуку, що поєднує лексичний та семантичний підходи, і до векторного пошуку з алгоритмом HNSW для роботи з ембедингами. Підтримка розгортання ML моделей безпосередньо в кластері Elasticsearch дозволяє реалізувати сучасні підходи до пошуку, включаючи пошук по зображеннях з використанням моделей типу CLIP або власних нейронних мереж.

Для інтернет-магазину рекомендується поетапний підхід до впровадження: спочатку традиційний повнотекстовий пошук з інвертованим індексом, потім гібридний пошук з комбінацією лексичного та семантичного пошуку, і нарешті пошук по зображеннях з використанням CLIP або власної моделі. Такий підхід дозволяє поступово покращувати користувацький досвід та конверсію, водночас контролюючи складність та витрати на інфраструктуру.

---

## Джерела

1. Elastic. "Elasticsearch: The Official Distributed Search & Analytics Engine." https://www.elastic.co/elasticsearch
2. Packt. "How does Elasticsearch work? [Tutorial]." https://hub.packtpub.com/how-does-elasticsearch-work-tutorial/
3. Medium. "Elasticsearch Architecture X: Exploration of the Inverted Index." https://braineanear.medium.com/elasticsearch-architecture-x-exploration-of-the-inverted-index-3928458a6a85
4. Elastic Blog. "Elasticsearch from the Bottom Up, Part 1." https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up
5. Stack Overflow. "What is elasticsearch index, Lucene index and inverted index." https://stackoverflow.com/questions/71816188/what-is-elasticsearch-index-lucene-index-and-inverted-index
6. Elastic. "Fast & scalable ecommerce search solutions." https://www.elastic.co/enterprise-search/ecommerce
7. Medium (Gigasearch). "Benchmarking Performance: Elasticsearch vs Competitors." https://medium.com/gigasearch/benchmarking-performance-elasticsearch-vs-competitors-d4778ef75639
8. Algolia Blog. "40+ stats on e-commerce search and KPIs." https://www.algolia.com/blog/ecommerce/e-commerce-search-and-kpis-statistics
9. Mailmodo. "21 eCommerce Site Search Statistics You Need to Know." https://www.mailmodo.com/guides/ecommerce-site-search-statistics/
10. Elastic. "Elasticsearch Benchmarks." https://elasticsearch-benchmarks.elastic.co/
11. Elastic Blog. "Elasticsearch vs. OpenSearch: Performance and resource utilization analysis." https://www.elastic.co/blog/elasticsearch-opensearch-performance-gap
12. Elastic. "A Comprehensive Hybrid Search Guide." https://www.elastic.co/what-is/hybrid-search
13. Elastic Docs. "Hybrid search with semantic_text." https://www.elastic.co/docs/solutions/search/hybrid-semantic-text
14. Elasticsearch Labs. "Lexical and semantic search with Elasticsearch." https://www.elastic.co/search-labs/blog/lexical-and-semantic-search-with-elasticsearch
15. Elastic Docs. "kNN search in Elasticsearch." https://www.elastic.co/docs/solutions/search/vector/knn
16. Elasticsearch Labs. "HNSW graph: How to improve Elasticsearch performance." https://www.elastic.co/search-labs/blog/hnsw-graph
17. Elastic Blog. "Introducing approximate nearest neighbor search in Elasticsearch 8.0." https://www.elastic.co/blog/introducing-approximate-nearest-neighbor-search-in-elasticsearch-8-0
18. GDELT Project. "Our Journey Towards User-Facing Vector Search: Evaluating Elasticsearch's ANN Vector Search RAM Costs." https://blog.gdeltproject.org/our-journey-towards-user-facing-vector-search-evaluating-elasticsearchs-ann-vector-search-ram-costs/
19. Elastic Blog. "Overview of image similarity search in Elastic." https://www.elastic.co/blog/overview-image-similarity-search-in-elastic
20. Pinecone. "Text-to-Image and Image-to-Image Search Using CLIP." https://www.pinecone.io/learn/clip-image-search/
21. OpenAI. "CLIP: Connecting text and images." https://openai.com/index/clip/
22. PyImageSearch. "Keras: Feature extraction on large datasets with Deep Learning." https://pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/
23. Medium. "Top 5 CNN Architectures to build your computer vision model." https://medium.com/@mukhriddinmalik/top-5-cnn-architectures-googlenet-resnet-densenet-alexnet-and-vggnet-to-build-your-computer-ca0c6f93512e
24. GeeksforGeeks. "Top Pre-Trained Models for Image Classification." https://www.geeksforgeeks.org/computer-vision/top-pre-trained-models-for-image-classification/
25. Medium. "Image Similarity using CNN feature embeddings." https://medium.com/@f.a.reid/image-similarity-using-feature-embeddings-357dc01514f8
26. Elastic Docs. "Deploy the model in your cluster." https://www.elastic.co/docs/explore-analyze/machine-learning/nlp/ml-nlp-deploy-model
27. Elastic Docs. "Add NLP inference to ingest pipelines." https://www.elastic.co/docs/explore-analyze/machine-learning/nlp/ml-nlp-inference
28. Elastic Docs. "ELSER." https://www.elastic.co/docs/explore-analyze/machine-learning/nlp/ml-nlp-elser
